{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEIOYjTwVlur"
      },
      "source": [
        "# Problem Statement\n",
        "We want to create a text summarizer model that takes a review and returns the summary of it.\n",
        "\n",
        "- Data: using \"Samsum\" data\n",
        "    - https://huggingface.co/datasets/samsum\n",
        "- Model: facebook/bart-large-cnn\"  \n",
        "    - https://huggingface.co/facebook/bart-large-cnn  \n",
        "We are going to fune-tune the model to work for samsum dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "578fCL9aV3bU"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-3oXe3sVlut",
        "outputId": "8a1f62b8-f7f1-4a25-e3a4-fc73e1452011"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset, load_metric\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bcInC_VzVluu",
        "outputId": "3bfc8f8d-cb22-4afe-a6bf-3c71dac10e53"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0KWeP8bBVluv"
      },
      "outputs": [],
      "source": [
        "model_ckpt = \"facebook/bart-large-cnn\"\n",
        "\n",
        "# loading the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "acWaxKl7Vluv"
      },
      "outputs": [],
      "source": [
        "model_summarizer = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hUMIW6KVVluv"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "dataset = load_dataset(\"samsum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MxJ1sEzVluv",
        "outputId": "94c07dee-e4d8-4a9a-8bf0-25c4cf43ac17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 14732\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 819\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 818\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p_mMX7AVluw",
        "outputId": "b54c040a-9b4b-46fe-dc7d-765cfd5ce0ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amanda: I baked  cookies. Do you want some?\r\n",
            "Jerry: Sure!\r\n",
            "Amanda: I'll bring you tomorrow :-)\n"
          ]
        }
      ],
      "source": [
        "print(dataset['train'][0]['dialogue'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsPyboOyVluw",
        "outputId": "27300ec7-0875-44bc-aeeb-a76845cc2c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amanda baked cookies and will bring Jerry some tomorrow.\n"
          ]
        }
      ],
      "source": [
        "print(dataset['train'][0]['summary'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueC0IF_GVluw",
        "outputId": "ef985b4e-5f86-414a-cf0a-891144259c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hannah: Hey, do you have Betty's number?\n",
            "Amanda: Lemme check\n",
            "Hannah: <file_gif>\n",
            "Amanda: Sorry, can't find it.\n",
            "Amanda: Ask Larry\n",
            "Amanda: He called her last time we were at the park together\n",
            "Hannah: I don't know him well\n",
            "Hannah: <file_gif>\n",
            "Amanda: Don't be shy, he's very nice\n",
            "Hannah: If you say so..\n",
            "Hannah: I'd rather you texted him\n",
            "Amanda: Just text him ðŸ™‚\n",
            "Hannah: Urgh.. Alright\n",
            "Hannah: Bye\n",
            "Amanda: Bye bye\n"
          ]
        }
      ],
      "source": [
        "dialogue = dataset['test'][0]['dialogue']\n",
        "print(dialogue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PUPilLK6Vluw"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(task=\"summarization\", model=model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrHEUr_MVlux",
        "outputId": "f7be5165-2c75-40f5-ed9e-6b08418cdd0c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your max_length is set to 142, but your input_length is only 139. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=69)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hannah asks Amanda for Betty's number. Amanda can't find it. Hannah asks Larry. Amanda asks Larry to text him. Hannah says she'll text him back. Hannah calls it a day and says she's going to go home. Hannah: \"Bye bye\"\n"
          ]
        }
      ],
      "source": [
        "# testing if the model works without fine-tuning it\n",
        "prediction = pipe(dialogue)\n",
        "print(prediction[0]['summary_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ySTMg3ypVlux"
      },
      "outputs": [],
      "source": [
        "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
        "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
        "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]\n",
        "\n",
        "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
        "                               batch_size=16, device=device,\n",
        "                               column_text=\"article\",\n",
        "                               column_summary=\"highlights\"):\n",
        "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for article_batch, target_batch in tqdm(\n",
        "        zip(article_batches, target_batches), total=len(article_batches)):\n",
        "\n",
        "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
        "                        padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
        "        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n",
        "\n",
        "        # Finally, we decode the generated texts,\n",
        "        # replace the  token, and add the decoded texts with the references to the metric.\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                clean_up_tokenization_spaces=True)\n",
        "               for s in summaries]\n",
        "\n",
        "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
        "\n",
        "\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "    #  Finally compute and return the ROUGE scores.\n",
        "    score = metric.compute()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hVjaUciqVlux"
      },
      "outputs": [],
      "source": [
        "# selecting just 10 samples, so it doesn't take a lot of time\n",
        "sample_test_data = dataset['test'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRmu8cPsVlux",
        "outputId": "3b6b64c8-ac31-4623-b9f2-b996c9e048fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-e660cda8d7d9>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge_metric = load_metric(\"rouge\")\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.48s/it]\n"
          ]
        }
      ],
      "source": [
        "rouge_metric = load_metric(\"rouge\")\n",
        "\n",
        "score = calculate_metric_on_test_ds(dataset=sample_test_data, metric=rouge_metric, model=model_summarizer,\n",
        "                                    tokenizer=tokenizer, batch_size=16, device=device, column_text=\"dialogue\", column_summary=\"summary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "qrzLYIqgVlux",
        "outputId": "dd384114-7873-4d73-f8b7-165100011a2b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4c67bb46-01b9-442e-a8a6-5ab59c9db7db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bart</th>\n",
              "      <td>0.016443</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01663</td>\n",
              "      <td>0.016482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c67bb46-01b9-442e-a8a6-5ab59c9db7db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c67bb46-01b9-442e-a8a6-5ab59c9db7db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c67bb46-01b9-442e-a8a6-5ab59c9db7db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        rouge1  rouge2   rougeL  rougeLsum\n",
              "bart  0.016443     0.0  0.01663   0.016482"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
        "\n",
        "pd.DataFrame(rouge_dict, index = ['bart'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW9bIpWHVlux"
      },
      "source": [
        "So bad, need to fune-tune it :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ayLnKL7AVlux",
        "outputId": "f0e55038-052a-4e20-8231-ebc6dae15251"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dialogue_token_len = len([tokenizer.encode(s) for s in dataset['train']['dialogue']])\n",
        "\n",
        "summary_token_len = len([tokenizer.encode(s) for s in dataset['train']['summary']])\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "axes[0].hist(dialogue_token_len, bins = 20, color = 'C0', edgecolor = 'C0' )\n",
        "axes[0].set_title(\"Dialogue Token Length\")\n",
        "axes[0].set_xlabel(\"Length\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "\n",
        "axes[1].hist(summary_token_len, bins = 20, color = 'C0', edgecolor = 'C0' )\n",
        "axes[1].set_title(\"Summary Token Length\")\n",
        "axes[1].set_xlabel(\"Length\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "8137f6aba31b4cb7bac09cb088160f31",
            "0addf87e0b224755a45283a592307d7d",
            "8311fae96b46406d9c2d91f6736ae8ed",
            "25ff601479564a14adb411193f88f7b6",
            "610e413761e9463faaf60951efeb4d68",
            "94eecb9c72674e13afc9220cfc69c3da",
            "9f6633a9e4614c18b86b72dbe385c474",
            "a9d4a7615bb245418cd3e305e439bf9d",
            "e52a08d7836147c69245aa4ea911182f",
            "265004a86feb4753ad05fa15a199b9a8",
            "dde20358dda240a2b48492154fd671c2"
          ]
        },
        "id": "f72mDjJXVluy",
        "outputId": "3aa0bb77-b475-4ec7-bc6b-7ce3dd428b1e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8137f6aba31b4cb7bac09cb088160f31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n",
        "\n",
        "    return {\n",
        "        'input_ids' : input_encodings['input_ids'],\n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'labels': target_encodings['input_ids']\n",
        "    }\n",
        "\n",
        "dataset_samsum_pt = dataset.map(convert_examples_to_features, batched = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPDcnep9Vluy",
        "outputId": "31c8788c-4aa0-472c-8828-1aebde73a91c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('13818513',\n",
              " \"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\",\n",
              " 'Amanda baked cookies and will bring Jerry some tomorrow.')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_encoding = dataset_samsum_pt['train'][0]\n",
        "sample_encoding['id'], sample_encoding['dialogue'], sample_encoding['summary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLvDGEMxVluy",
        "outputId": "3f2ec765-cfa6-4fc2-91f4-e00b537b09fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([0,\n",
              "  10127,\n",
              "  5219,\n",
              "  35,\n",
              "  38,\n",
              "  17241,\n",
              "  1437,\n",
              "  15269,\n",
              "  4,\n",
              "  1832,\n",
              "  47,\n",
              "  236,\n",
              "  103,\n",
              "  116,\n",
              "  50121,\n",
              "  50118,\n",
              "  39237,\n",
              "  35,\n",
              "  9136,\n",
              "  328,\n",
              "  50121,\n",
              "  50118,\n",
              "  10127,\n",
              "  5219,\n",
              "  35,\n",
              "  38,\n",
              "  581,\n",
              "  836,\n",
              "  47,\n",
              "  3859,\n",
              "  48433,\n",
              "  2],\n",
              " [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1],\n",
              " [0, 10127, 5219, 17241, 15269, 8, 40, 836, 6509, 103, 3859, 4, 2])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_encoding['input_ids'], sample_encoding['attention_mask'], sample_encoding['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YEcdEMGZVluy"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2seq_data_collector = DataCollatorForSeq2Seq(tokenizer, model=model_summarizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2_hJACoWnvW",
        "outputId": "b56baec6-36d2-40aa-8973-e89699989bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "z3yR5pc3Vluy",
        "outputId": "3e22fe4a-69af-480c-fbe6-0c0a4ad83004"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [920/920 40:39, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.436700</td>\n",
              "      <td>1.475281</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=920, training_loss=1.386543481246285, metrics={'train_runtime': 2444.4252, 'train_samples_per_second': 6.027, 'train_steps_per_second': 0.376, 'total_flos': 4938562616451072.0, 'train_loss': 1.386543481246285, 'epoch': 1.0})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir='bart-samsum', num_train_epochs=1, warmup_steps=500,\n",
        "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01, logging_steps=10,\n",
        "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
        "    gradient_accumulation_steps=16\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(model=model_summarizer, args=trainer_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2seq_data_collector,\n",
        "                  train_dataset=dataset_samsum_pt[\"train\"],\n",
        "                  eval_dataset=dataset_samsum_pt[\"validation\"])\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ5HBRvcYXRJ"
      },
      "source": [
        "This was trained on colab since training it locally is impossible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "gynBKl_ZVluy",
        "outputId": "9c5fa0f6-b141-40e9-92f7-0e74b05a4d11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:19<00:00,  3.85s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1a836235-d9e3-47ff-8376-67a05ad75f91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bart</th>\n",
              "      <td>0.016005</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016249</td>\n",
              "      <td>0.015898</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a836235-d9e3-47ff-8376-67a05ad75f91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a836235-d9e3-47ff-8376-67a05ad75f91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a836235-d9e3-47ff-8376-67a05ad75f91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        rouge1  rouge2    rougeL  rougeLsum\n",
              "bart  0.016005     0.0  0.016249   0.015898"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# testing the score again to see if it's improved\n",
        "score = calculate_metric_on_test_ds(\n",
        "    sample_test_data, rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",
        ")\n",
        "\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
        "\n",
        "pd.DataFrame(rouge_dict, index = [f'bart'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTjxbwPjkFFc"
      },
      "outputs": [],
      "source": [
        "# rouge1\trouge2\trougeL\trougeLsum\n",
        "# bart\t0.016443\t0.0\t0.01663\t0.016482"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIxBEygvVluy",
        "outputId": "099fa5a5-be80-44ae-eed1-f3b2537e6aad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.json',\n",
              " 'tokenizer/merges.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# save pretrained model and the tokenizer\n",
        "model_summarizer.save_pretrained(\"tuned-bart-samsum\")\n",
        "\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tip2NcGvWhMk",
        "outputId": "bc8fdd71-570e-4ec8-ebfd-3b418a753299"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14732\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 819\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 818\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_samsum_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwo87OTEXXfL",
        "outputId": "5a5c4e25-c1dd-490e-93a6-35b0ba870900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/tokenizer/ (stored 0%)\n",
            "  adding: content/tokenizer/tokenizer_config.json (deflated 76%)\n",
            "  adding: content/tokenizer/special_tokens_map.json (deflated 52%)\n",
            "  adding: content/tokenizer/vocab.json (deflated 59%)\n",
            "  adding: content/tokenizer/merges.txt (deflated 53%)\n",
            "  adding: content/tokenizer/tokenizer.json (deflated 72%)\n"
          ]
        }
      ],
      "source": [
        "# to download the model and tokenizer\n",
        "!zip -r /content/tokenizer.zip /content/tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVlY5S-miGns",
        "outputId": "fef69c78-cd3d-4369-8006-ba0cc1e3bdbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/tuned-bart-samsum/ (stored 0%)\n",
            "  adding: content/tuned-bart-samsum/model.safetensors (deflated 7%)\n",
            "  adding: content/tuned-bart-samsum/generation_config.json (deflated 47%)\n",
            "  adding: content/tuned-bart-samsum/config.json (deflated 61%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/tuned-bart-samsum.zip /content/tuned-bart-samsum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "flO9zPR_jWOL",
        "outputId": "a8529874-7c1f-4cbd-afbb-cf083015f769"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b3e5da56-1cb8-4d65-aa32-7e511c68bb18\", \"tuned-bart-samsum.zip\", 1506840046)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/tuned-bart-samsum.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUbkdn7sZCn0"
      },
      "source": [
        "## Inference using our trained (tuned) model\n",
        "\n",
        "tokenizer and tuned-bart-samsum that are in artifacts are created then downloaded through google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXtV0cSWZQrX",
        "outputId": "88ecbdac-35f9-4ddf-ba53-642248879dca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVHYBhOnZTzq",
        "outputId": "91c31e07-5d42-4931-ca89-89f8837e8c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bart-samsum  sample_data  tokenizer  tokenizer.zip  tuned-bart-samsum  tuned-bart-samsum.zip\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VSnuVrrPZI4H"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"../artifacts/tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iNLIPk9nZd59"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"samsum\")\n",
        "\n",
        "sample_text = dataset[\"test\"][0][\"dialogue\"]\n",
        "reference = dataset[\"test\"][0][\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCYJAlVhZsTc",
        "outputId": "cb7ec2e6-6d07-48cb-c638-1de9badfe2ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hannah: Hey, do you have Betty's number?\n",
            "Amanda: Lemme check\n",
            "Hannah: <file_gif>\n",
            "Amanda: Sorry, can't find it.\n",
            "Amanda: Ask Larry\n",
            "Amanda: He called her last time we were at the park together\n",
            "Hannah: I don't know him well\n",
            "Hannah: <file_gif>\n",
            "Amanda: Don't be shy, he's very nice\n",
            "Hannah: If you say so..\n",
            "Hannah: I'd rather you texted him\n",
            "Amanda: Just text him ðŸ™‚\n",
            "Hannah: Urgh.. Alright\n",
            "Hannah: Bye\n",
            "Amanda: Bye bye\n"
          ]
        }
      ],
      "source": [
        "print(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RJAnlX4QZwMc",
        "outputId": "933b12f3-392e-404d-ac96-59a45be5b259"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CehhpZfLZxRQ"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "tuned-bart-samsum is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[0;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
            "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/tuned-bart-samsum/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\transformers\\utils\\hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    429\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    431\u001b[0m         path_or_repo_id,\n\u001b[0;32m    432\u001b[0m         filename,\n\u001b[0;32m    433\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    434\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m    435\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    436\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    437\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    438\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    439\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    440\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    441\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m    442\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    443\u001b[0m     )\n\u001b[0;32m    444\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1346\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1345\u001b[0m     \u001b[39m# Repo not found => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1346\u001b[0m     \u001b[39mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1347\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     \u001b[39m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1232\u001b[0m     metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[0;32m   1233\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m   1234\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   1235\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1236\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[0;32m   1237\u001b[0m     )\n\u001b[0;32m   1238\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[0;32m   1239\u001b[0m     \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1608\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[0;32m   1599\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1600\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1601\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1606\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m   1607\u001b[0m )\n\u001b[1;32m-> 1608\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   1610\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:293\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    285\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[0;32m    286\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m make sure you are authenticated.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m     )\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m400\u001b[39m:\n",
            "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-65464bc9-05f9d2c51302ac821dceb770;46f31f15-a1c3-4b7d-9b77-387eff598356)\n\nRepository Not Found for url: https://huggingface.co/tuned-bart-samsum/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\notebooks\\Model_Summarization_Fine_Tuning_LLM.ipynb Cell 42\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/Projects/Data%20Science/Projects/Text-Summarization/notebooks/Model_Summarization_Fine_Tuning_LLM.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gen_kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mlength_penalty\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.8\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnum_beams\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m8\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m128\u001b[39m}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/Projects/Data%20Science/Projects/Text-Summarization/notebooks/Model_Summarization_Fine_Tuning_LLM.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39msummarization\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtuned-bart-samsum\u001b[39;49m\u001b[39m\"\u001b[39;49m, tokenizer\u001b[39m=\u001b[39;49mtokenizer)\n",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\transformers\\pipelines\\__init__.py:747\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m     pretrained_model_name_or_path \u001b[39m=\u001b[39m model\n\u001b[0;32m    745\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig) \u001b[39mand\u001b[39;00m pretrained_model_name_or_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    746\u001b[0m     \u001b[39m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m--> 747\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[0;32m    748\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    749\u001b[0m         CONFIG_NAME,\n\u001b[0;32m    750\u001b[0m         _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    751\u001b[0m         _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    752\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    753\u001b[0m     )\n\u001b[0;32m    754\u001b[0m     hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    755\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\user\\Documents\\Projects\\Data Science\\Projects\\Text-Summarization\\venv\\lib\\site-packages\\transformers\\utils\\hub.py:451\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    455\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`token=<your_token>`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[39mexcept\u001b[39;00m RevisionNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    459\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfor this model name. Check the model page at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for available revisions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "\u001b[1;31mOSError\u001b[0m: tuned-bart-samsum is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ],
      "source": [
        "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\": 8, \"max_length\": 128}\n",
        "\n",
        "pipe = pipeline(\"summarization\", model=\"tuned-bart-samsum\", tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6cOAEsAaUDh",
        "outputId": "4f49b0e4-4f3f-4acd-e0f2-5c34da8ac2f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amanda can't find Betty's number. Larry called Betty the last time they were at the park together. Hannah advises Amanda to text him to ask him for Betty's phone number. Hannah and Larry don't know each other well, so Hannah would rather Amanda texted him.\n"
          ]
        }
      ],
      "source": [
        "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBNOUgCyjzlC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0addf87e0b224755a45283a592307d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94eecb9c72674e13afc9220cfc69c3da",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9f6633a9e4614c18b86b72dbe385c474",
            "value": "Map: 100%"
          }
        },
        "25ff601479564a14adb411193f88f7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265004a86feb4753ad05fa15a199b9a8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dde20358dda240a2b48492154fd671c2",
            "value": " 819/819 [00:00&lt;00:00, 2039.33 examples/s]"
          }
        },
        "265004a86feb4753ad05fa15a199b9a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610e413761e9463faaf60951efeb4d68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8137f6aba31b4cb7bac09cb088160f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0addf87e0b224755a45283a592307d7d",
              "IPY_MODEL_8311fae96b46406d9c2d91f6736ae8ed",
              "IPY_MODEL_25ff601479564a14adb411193f88f7b6"
            ],
            "layout": "IPY_MODEL_610e413761e9463faaf60951efeb4d68"
          }
        },
        "8311fae96b46406d9c2d91f6736ae8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d4a7615bb245418cd3e305e439bf9d",
            "max": 819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e52a08d7836147c69245aa4ea911182f",
            "value": 819
          }
        },
        "94eecb9c72674e13afc9220cfc69c3da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6633a9e4614c18b86b72dbe385c474": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9d4a7615bb245418cd3e305e439bf9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde20358dda240a2b48492154fd671c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e52a08d7836147c69245aa4ea911182f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
